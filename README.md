# PlasmaJet-RL
Reinforcement learning-driven intelligent control system for ETOP-based medical plasma jet dose.

### Project Overview

This project utilizes the **Proximal Policy Optimization (PPO)** algorithm, a technique in **Reinforcement Learning (RL)**, to develop an intelligent control system for regulating the **Electron Transfer Optimized Plasma density (ETOP density)** of reactive species in an **Atmospheric Pressure Plasma Jet (APPJ)** system. By training a PPO agent, the system dynamically adjusts control parameters—such as **voltage**, **oxygen concentration**, and **gas flow rate**—in real-time to maintain a stable ETOP density that aligns with a preset target. This approach tackles the challenge of density instability in **plasma medicine**, which arises due to environmental disturbances or parameter fluctuations, ultimately enhancing the precision and reliability of treatments.

---

### Project Background

**Plasma medicine** leverages reactive species (e.g., **NO**, **O**, **OH**) generated by low-temperature plasma to achieve specific biological effects, such as promoting **wound healing** or **killing pathogens**. However, the nonlinear and dynamic nature of plasma systems poses significant challenges for manually adjusting parameters to maintain a stable ETOP density. External factors, such as **changes in moisture content**, or operational conditions, like **flow rate fluctuations**, can cause density deviations, negatively impacting treatment efficacy. Consequently, there is a pressing need in plasma medicine for an intelligent control system capable of autonomously optimizing these parameters.

---

### Project Objectives

The project is designed with three distinct operational modes, each with specific goals:

- **Training Mode (train=1)**:  
  Train an intelligent PPO agent to adjust control parameters based on randomly generated target densities, minimizing the deviation between the output ETOP density and the target value.

- **Baseline Tracking Test Mode (train=2)**:  
  Validate the system's ability to track complex target density sequences—including **linear changes**, **sinusoidal fluctuations**, and **steady phases**—using a pre-trained model, assessing its dynamic response performance.

- **Disturbance Rejection Test Mode (train=3)**:  
  Test the system's stability in maintaining fixed target densities under external disturbances (e.g., **moisture content changes**), ensuring its robustness.

---

### Project Methodology

#### Environment Simulation
The project uses pre-trained **Deep Neural Network (DNN)** models—namely `SysModel_NO`, `SysModel_O`, and `SysModel_OH`—to predict the densities of reactive species such as **NO**, **O**, and **OH**. These models take input parameters (e.g., **voltage**, **oxygen concentration**, **flow rate**, **moisture content**) and generate density predictions. The **ETOP density** is then computed through weighted calculations, simulating the physical behavior of the APPJ system.

#### PPO Algorithm
The PPO agent comprises two networks:
- **Actor Network**: Outputs a probability distribution of actions based on the current state (density deviation and historical actions) to adjust control parameters.
- **Critic Network**: Evaluates the state value to guide policy optimization.  
PPO employs a **clipped surrogate objective** to ensure training stability.

#### Reward Mechanism
The reward function is defined as the negative of the density deviation:  
`-k * |target_density - output_density|`,  
encouraging the agent to minimize this deviation. An additional reward of **+10** is awarded when the deviation falls below **0.01**, accelerating convergence.

#### Multi-Mode Operation
- **Training Mode**: The agent interacts with the environment, collects experience, updates network parameters, and saves the optimal model.
- **Baseline Tracking Mode**: Loads the trained model to test its performance on a `test_seq` sequence (linear, sinusoidal, and steady phases), with results recorded in graphs and CSV files.
- **Disturbance Rejection Mode**: Introduces **moisture disturbances** at fixed target densities to evaluate the system's stable control capability.

---

### Project Structure

- **Main Program (main.py)**:  
  Defines training and testing workflows, initializes the `Jet` environment and `PPO` agent, executes tasks based on the `train` mode (1, 2, or 3), and visualizes results.

- **Jet Class**:  
  Simulates the plasma jet environment, handling:
  - State updates (density deviation and action concatenation),
  - Action execution (calling DNNs to predict density),
  - Reward calculation.  
  Both action and state spaces are continuous `Box` types with a range of **[0, 1]**.

- **PPO Class**:  
  Implements the PPO algorithm, including the construction of **Actor** and **Critic** networks, action selection, experience storage, and training updates. It leverages **TensorFlow 1.x**’s static graph mode for enhanced performance.

---

### Project Significance

By integrating **reinforcement learning** with **deep learning**, this project achieves intelligent control of ETOP density in plasma jet systems, offering an efficient automated solution for **plasma medicine**. The system maintains target densities in dynamic environments and under external disturbances, improving treatment **precision** and **stability**. It also lays the technical foundation for future autonomous plasma medical devices.

---

### Technical Highlights

- **Reinforcement Learning Optimization**:  
  The combination of PPO and DNN models effectively addresses the nonlinear dynamic characteristics of plasma systems.
- **Multi-Scenario Validation**:  
  Comprehensive evaluation through baseline tracking and disturbance rejection tests ensures dynamic performance and robustness.
- **Real-Time Capability**:  
  Supports **millisecond-level** parameter adjustments to meet rapidly changing treatment needs.

---

### Application Prospects

This control system can be directly applied to **plasma medical devices**, enabling clinicians to precisely regulate the ETOP density of reactive species, thereby enhancing **treatment efficacy** and **safety**. Furthermore, the technology has potential applications in other fields requiring precise control of reactive species, such as **material surface modification** or **air purification**.
